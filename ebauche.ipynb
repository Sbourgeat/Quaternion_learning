{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d03444e5-377a-4d9f-91a0-d4f1c818f42d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T12:56:47.155454Z",
     "iopub.status.busy": "2024-08-19T12:56:47.154430Z",
     "iopub.status.idle": "2024-08-19T12:56:47.171062Z",
     "shell.execute_reply": "2024-08-19T12:56:47.168479Z",
     "shell.execute_reply.started": "2024-08-19T12:56:47.155365Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy.ndimage import map_coordinates\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c10c9caf-77cf-41a1-aa7b-65d799d73192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T12:56:47.449683Z",
     "iopub.status.busy": "2024-08-19T12:56:47.448735Z",
     "iopub.status.idle": "2024-08-19T12:56:47.459368Z",
     "shell.execute_reply": "2024-08-19T12:56:47.457221Z",
     "shell.execute_reply.started": "2024-08-19T12:56:47.449610Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#la première étape de notre projet consiste à prendre une image de cerveau de mouche et a determiner dans quel orientation il se situe \n",
    "#dans lespace à l'aide de quaternion. Pour cela nous avons recours à une PCA (principal component analysis) pour determiner les plus \n",
    "#grand axes du cerveau.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98ea8572-9af2-4663-b6e8-9705308126e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T12:56:47.886306Z",
     "iopub.status.busy": "2024-08-19T12:56:47.885493Z",
     "iopub.status.idle": "2024-08-19T12:56:47.900270Z",
     "shell.execute_reply": "2024-08-19T12:56:47.898093Z",
     "shell.execute_reply.started": "2024-08-19T12:56:47.886240Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rotate_image_along_longest_axes(image):\n",
    "    # Step 1: Extract coordinates of non-zero voxels\n",
    "    activated_coords = np.array(np.where(image > 0)).T\n",
    "\n",
    "    # Step 2: Perform PCA\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(activated_coords)\n",
    "\n",
    "    # Get the principal components\n",
    "    principal_components = pca.components_\n",
    "\n",
    "    # Step 3: Use the principal components to define a rotation quaternion\n",
    "    rotation_matrix = principal_components.T\n",
    "    rotation_quaternion = R.from_matrix(rotation_matrix).as_quat()\n",
    "\n",
    "    return rotation_quaternion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "539823de-54eb-4bf7-8e87-72e8933f4fa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T12:58:06.101816Z",
     "iopub.status.busy": "2024-08-19T12:58:06.100851Z",
     "iopub.status.idle": "2024-08-19T12:58:06.166750Z",
     "shell.execute_reply": "2024-08-19T12:58:06.165240Z",
     "shell.execute_reply.started": "2024-08-19T12:58:06.101739Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Directory C:/Users/Aurélien Delille/OneDrive - Saint Louis de Gonzague/Documents/epfl/project_bachelor/image_rotated/rotated_source already exists!\n",
      "Le dossier spécifié n'existe pas : C:/Users/Aurélien Delille/OneDrive - Saint Louis de Gonzague/Documents/epfl/project_bachelor/image_raw/source\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Aurélien Delille/OneDrive - Saint Louis de Gonzague/Documents/epfl/project_bachelor/image_raw/source'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(input_dir):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLe dossier spécifié n\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexiste pas : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# check if fly already done if fly id exists in one folder name\u001b[39;00m\n\u001b[1;32m     18\u001b[0m         INPUT_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir, file)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Aurélien Delille/OneDrive - Saint Louis de Gonzague/Documents/epfl/project_bachelor/image_raw/source'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    input_dir = \"C:/Users/Aurélien Delille/OneDrive - Saint Louis de Gonzague/Documents/epfl/project_bachelor/image_raw/source\"\n",
    "    # iterate over all the images in a given folder\n",
    "    OUTPUT_DIR = \"C:/Users/Aurélien Delille/OneDrive - Saint Louis de Gonzague/Documents/epfl/project_bachelor/image_rotated/rotated_source\"\n",
    "\n",
    "    if os.path.exists(OUTPUT_DIR):\n",
    "        print(f\" Directory {OUTPUT_DIR} already exists!\")\n",
    "        # otherwise mkdir\n",
    "    else:\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"Le dossier spécifié n'existe pas : {input_dir}\")\n",
    "\n",
    "    for file in tqdm(os.listdir(input_dir)):\n",
    "        if file.endswith(\".tif\"):\n",
    "            # check if fly already done if fly id exists in one folder name\n",
    "            INPUT_PATH = os.path.join(input_dir, file)\n",
    "            fly_id = INPUT_PATH.split('/')[-1].split('.')[0]\n",
    "            print(f\"Orienting fly: {fly_id}\")\n",
    "            # check if the file persistence_entropy_{fly_id}.csv exists in the\n",
    "            # folder\n",
    "            # /home/samuel/brainMorpho/Analysis_results/homology2voxel_pairwise/\n",
    "            # if it exists, skip the fly\n",
    "            filename = f\"rotated_{fly_id}.tif\"\n",
    "\n",
    "            # check if output dir exists\n",
    "            \n",
    "            if os.path.exists(os.path.join(OUTPUT_DIR,filename)):\n",
    "                pass\n",
    "            original_image = tiff.imread(INPUT_PATH)\n",
    "\n",
    "            quaternion = rotate_image_along_longest_axes(padded_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b0c21-c901-4bc4-bdc1-c83e7b5d3f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On définit ensuite notre classe et notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5881b70-243b-4c94-a774-8a41c311f55a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T11:12:24.177095Z",
     "iopub.status.busy": "2024-08-19T11:12:24.176731Z",
     "iopub.status.idle": "2024-08-19T11:12:24.189523Z",
     "shell.execute_reply": "2024-08-19T11:12:24.187226Z",
     "shell.execute_reply.started": "2024-08-19T11:12:24.177067Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class fly_alignement(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(fly_alignement, self).__init__()\n",
    "        \n",
    "        #Locally connected convolutiv layer\n",
    "        self.conv1 = nn.Conv3d(in_channels = 1, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n",
    "        # stride : number of pixels by which we move the filter across the input image.\n",
    "        # in channels : input data\n",
    "        # out channels : number of unique features or patterns that a convolutional neural network (CNN) can learn and extract from an input image\n",
    "        # padding : addition of extra pixels around the borders of the input images or feature map\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.bn1 = nn.BatchNorm3d(32)\n",
    "        # Normalisation est de stabiliser et d'accélérer le processus d'apprentissage, en réduisant la sensibilité du réseau aux variations des valeurs d'entrée.\n",
    "        \n",
    "        #Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 32 * 32 * 32, 128)  # size of the volume\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):# définit la manière dont les données passent à travers les différentes couches du réseau pour produire une sortie.\n",
    "        x = self.pool1(self.bn1(torch.relu(self.conv1(x))))\n",
    "        \n",
    "        # Aplatir le tenseur pour les couches entièrement connectées\n",
    "        x = x.view(-1, 32 * 32 * 32 * 32)  # redimensionne le tenseur\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "defa6d1f-0bf4-4c2f-92e7-3c99ee46ae3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T11:25:38.668373Z",
     "iopub.status.busy": "2024-08-19T11:25:38.667166Z",
     "iopub.status.idle": "2024-08-19T11:25:38.690387Z",
     "shell.execute_reply": "2024-08-19T11:25:38.687722Z",
     "shell.execute_reply.started": "2024-08-19T11:25:38.668244Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VolumeDataset(Dataset):\n",
    "    def __init__(self, volumes, labels):\n",
    "        self.volumes = volumes\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.volumes)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        volume = self.volumes[idx]\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(volume, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4599d3c-c5b1-4e5f-a296-59ebcec5e9aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T11:31:24.342375Z",
     "iopub.status.busy": "2024-08-19T11:31:24.341326Z",
     "iopub.status.idle": "2024-08-19T11:31:24.361330Z",
     "shell.execute_reply": "2024-08-19T11:31:24.358433Z",
     "shell.execute_reply.started": "2024-08-19T11:31:24.342292Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def QuaternionLoss(q_pred, q_target):\n",
    "        \n",
    "        # Normalisation des quaternions (pour s'assurer qu'ils sont unitaires)\n",
    "        q_pred = q_pred / torch.norm(q_pred, dim=-1, keepdim=True)\n",
    "        q_target = q_target / torch.norm(q_target, dim=-1, keepdim=True)\n",
    "        \n",
    "        # Calcul du produit scalaire entre les quaternions prédits et cibles\n",
    "        dot_product = torch.sum(q_pred * q_target, dim=-1)\n",
    "        \n",
    "        # Calcul de la perte : 1 - (dot_product ** 2)\n",
    "        loss = 1.0 - dot_product ** 2\n",
    "        \n",
    "        # Moyenne de la perte pour le batch\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d1e9806-c178-4752-bd9c-afb3c79266c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T11:31:43.851749Z",
     "iopub.status.busy": "2024-08-19T11:31:43.850878Z",
     "iopub.status.idle": "2024-08-19T11:37:24.370600Z",
     "shell.execute_reply": "2024-08-19T11:37:24.353648Z",
     "shell.execute_reply.started": "2024-08-19T11:31:43.851670Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m fly_alignement(num_classes \u001b[38;5;241m=\u001b[39m num_classes)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Instancier la fonction de perte\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m criterion \u001b[38;5;241m=\u001b[39m QuaternionLoss(\u001b[43mq_pred\u001b[49m, q_target)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Calculer la perte\u001b[39;00m\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(q_pred, q_target)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'q_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Hyperparamètres\n",
    "input_shape = (1, 64, 64, 64)  # Par exemple, volume de 64x64x64 avec 1 canal (grayscale)\n",
    "num_classes = 6  # Par exemple, 6 orientations possibles\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "\n",
    "model = fly_alignement(num_classes = num_classes)\n",
    "\n",
    "\n",
    "# Instancier la fonction de perte\n",
    "criterion = QuaternionLoss(q_pred, q_target)\n",
    "\n",
    "# Calculer la perte\n",
    "loss = criterion(q_pred, q_target)\n",
    "\n",
    "print(f'Loss: {loss.item()}')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a92883-cc6a-4ab3-bbdd-8c0449874daa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
