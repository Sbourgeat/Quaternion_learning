{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6f08331-1454-48ec-bc3e-f251f427c6ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T12:41:58.182406Z",
     "iopub.status.busy": "2024-08-23T12:41:58.180916Z",
     "iopub.status.idle": "2024-08-23T12:41:58.197451Z",
     "shell.execute_reply": "2024-08-23T12:41:58.195491Z",
     "shell.execute_reply.started": "2024-08-23T12:41:58.182299Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d9d8cd5-7a32-4fce-a2c0-7346d2789f96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T12:41:58.825074Z",
     "iopub.status.busy": "2024-08-23T12:41:58.824190Z",
     "iopub.status.idle": "2024-08-23T12:41:58.843329Z",
     "shell.execute_reply": "2024-08-23T12:41:58.841216Z",
     "shell.execute_reply.started": "2024-08-23T12:41:58.824999Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_images(directory_path, target_shape):\n",
    "    images = []\n",
    "    target_shape = (target_shape, target_shape, target_shape)\n",
    "    for filename in sorted(os.listdir(directory_path)):\n",
    "        if filename.endswith(\".tif\"):\n",
    "            image = tiff.imread(os.path.join(directory_path, filename))\n",
    "            if image.shape != target_shape:\n",
    "                image = resize(\n",
    "                    image, target_shape, preserve_range=True, anti_aliasing=True\n",
    "                )\n",
    "                image = image.astype(np.float32)\n",
    "            images.append(image)\n",
    "    images = np.array(images)\n",
    "    images = np.expand_dims(images, axis=-1)  # Add channel dimension\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1492effb-80dc-4392-a690-82e8109f1fb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T12:41:59.206703Z",
     "iopub.status.busy": "2024-08-23T12:41:59.205894Z",
     "iopub.status.idle": "2024-08-23T12:41:59.221876Z",
     "shell.execute_reply": "2024-08-23T12:41:59.219147Z",
     "shell.execute_reply.started": "2024-08-23T12:41:59.206633Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(source_images):\n",
    "    normalized_images = []\n",
    "    for img in source_images:\n",
    "        min_val = np.min(img)\n",
    "        max_val = np.max(img)\n",
    "        normalized_img = (img - min_val) / (max_val - min_val + np.finfo(float).eps)\n",
    "        normalized_images.append(normalized_img)\n",
    "    normalized_images = np.array(normalized_images)\n",
    "    normalized_images = np.clip(normalized_images, 0, 1)\n",
    "    normalized_images = normalized_images.astype(np.float32)\n",
    "    return normalized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3aaee99-a631-48a7-9760-404a2461f54e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T12:44:03.844604Z",
     "iopub.status.busy": "2024-08-23T12:44:03.843705Z",
     "iopub.status.idle": "2024-08-23T12:44:03.861466Z",
     "shell.execute_reply": "2024-08-23T12:44:03.859097Z",
     "shell.execute_reply.started": "2024-08-23T12:44:03.844522Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def binarize_targets(target_path, threshold = 0.1):\n",
    "    binarized_image = []\n",
    "    for targets in target_path:\n",
    "        targets[targets >= threshold] = 1\n",
    "        targets[targets < threshold] = 0\n",
    "        binarized_image.append(targets)\n",
    "\n",
    "    targets = np.array(binarized_image)\n",
    "    targets = np.clip(targets, 0, 1)\n",
    "    targets = targets.astype(np.float32)\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd68e86-e6e7-4990-977f-88a468eeb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, source_images, downsampling_factor):\n",
    "        self.source_images = torch.tensor(source_images, dtype=torch.float32)\n",
    "        self.source_images = self.source_images.permute(0, 4, 2, 3, 1)\n",
    "        self.source_images = torch.nn.functional.interpolate(\n",
    "            self.source_images, scale_factor=1 / downsampling_factor\n",
    "        )\n",
    "        self.source_images = self.source_images.permute(0, 2, 3, 4, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.source_images[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d44d741-4def-42ae-b2ac-5ba47882f64a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T13:05:26.067088Z",
     "iopub.status.busy": "2024-08-23T13:05:26.065193Z",
     "iopub.status.idle": "2024-08-23T13:05:26.198456Z",
     "shell.execute_reply": "2024-08-23T13:05:26.196810Z",
     "shell.execute_reply.started": "2024-08-23T13:05:26.066990Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 66\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Simulation d'un ensemble de données volumétriques (synthetique pour l'exemple)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# volumes_train = torch.randn(100, 1, 32, 32, 32)  # Exemple de volumes 3D de 32x32x32\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# labels_train = torch.randn(100, 4)  # Quaternions associés\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# DataLoader\u001b[39;00m\n\u001b[1;32m     65\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m---> 66\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mtrain_set\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     67\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_set, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Instantiation du modèle\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "# Définition du modèle\n",
    "class OrientationNetQuaternion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OrientationNetQuaternion, self).__init__()\n",
    "        # 3D convolutional layers\n",
    "        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8 * 8, 512)  # Adjust according to input size\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 4)  # Output 4 quaternions\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool3d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool3d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool3d(x, 2)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # Output the quaternion\n",
    "        return x\n",
    "\n",
    "# Fonction d'entraînement\n",
    "def train_model(model, criterion, optimizer, train_loader, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for volumes, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(volumes)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Fonction de test\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for volumes, labels in test_loader:\n",
    "            outputs = model(volumes)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    print(f'Average test loss: {total_loss/len(test_loader):.4f}')\n",
    "\n",
    "# Conversion en TensorDataset\n",
    "# train_set = TensorDataset(volumes_train, labels_train)\n",
    "# test_set = TensorDataset(volumes_test, labels_test)\n",
    "\n",
    "# Définition de la fonction de perte et de l'optimiseur\n",
    "criterion = nn.MSELoss()  # Utilisé pour la régression de quaternions\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entraînement du modèle\n",
    "num_epochs = 10\n",
    "train_model(model, criterion, optimizer, train_loader, num_epochs)\n",
    "\n",
    "# Test du modèle\n",
    "test_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a467887f-342a-4514-95e4-b82c4569ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Hard-coded configuration\n",
    "    config = Config()\n",
    "    config.model_path = \"./model_3d_opti.pth\"  # Change to your model path\n",
    "    config.input_dir = \"./training/source/\"  # Change to your input images directory\n",
    "    config.output_dir = \"./predictions\"  # Change to your output directory\n",
    "    config.batch_size = 1\n",
    "    config.target_shape = 192\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the model\n",
    "    model = OrientationNetQuaternion()\n",
    "    model.load_state_dict(torch.load(config.model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Load the input images\n",
    "    input_images = load_images(config.input_dir, config.target_shape)\n",
    "    original_shape = input_images[0].shape\n",
    "    input_images = normalize(input_images)\n",
    "\n",
    "    # Create the dataset and dataloader\n",
    "    dataset = CustomDataset(input_images)\n",
    "    dataloader = DataLoader(dataset, batch_size = config.batch_size, shuffle=False)\n",
    "\n",
    "    # Perform predictions\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "    # Save the predictions\n",
    "    save_predictions(predictions, config.output_dir, original_shape)\n",
    "    print(f\"Predictions saved to {config.output_dir}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
